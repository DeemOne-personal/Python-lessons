{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "Copy of homework_2_poetry_generation_TEST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeemOne-personal/Python-lessons/blob/main/Copy_of_homework_2_poetry_generation_FAIL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Quao1WwFPOvn"
      },
      "source": [
        "## Homework №2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txzufAHoPOvo"
      },
      "source": [
        "### Almost Shakespeare\n",
        "\n",
        "Let's try to generate some Shakespeare poetry using RNNs. The sonnets file is available in the notebook directory.\n",
        "\n",
        "Text generation can be designed in several steps:\n",
        "    \n",
        "1. Data loading.\n",
        "2. Dictionary generation.\n",
        "3. Data preprocessing.\n",
        "4. Model (neural network) training.\n",
        "5. Text generation (model evaluation).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUPTdS1BPOvp"
      },
      "source": [
        "### Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KyYA5dZPOvp"
      },
      "source": [
        "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`).\n",
        "\n",
        "Simple preprocessing is already done for you in the next cell: all technical info is dropped."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8rI-T6qjkly"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "hERfiZL8POvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4cbeae8-c1e4-4954-f5fc-183efd5dd1f6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Edu4 - DS MFTI Adv/Files/HW2/sonnets.txt', 'r') as iofile:\n",
        "    source_text = iofile.readlines()\n",
        "    \n",
        "TEXT_START = 45\n",
        "TEXT_END = -368\n",
        "names = source_text[TEXT_START : TEXT_END]\n",
        "assert len(names) == 2616\n",
        "start_token = \" \""
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR4As896-ce-"
      },
      "source": [
        "import re\n",
        "fullstr=''.join(line for line in names).lower()\n",
        "fullstr = re.sub(r'[^\\w]', ' ', fullstr)\n",
        "fullstr=re.sub(' +', ' ', fullstr)\n",
        "names=fullstr"
      ],
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j7isOykPOvq"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZjUQri8POvr"
      },
      "source": [
        "Put all the characters, that you've seen in the text, into variable `tokens`.\n",
        "\n",
        "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN-5CJLzmBYl"
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length =\", MAX_LENGTH)\n",
        "\n",
        "plt.title(\"Sequence length distribution\")\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCT6SDxrPOvs"
      },
      "source": [
        "*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-j5uf_-POvt"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4go5JugdPOvt"
      },
      "source": [
        "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
        "\n",
        "Let's use vanilla RNN, similar to the one created during the lesson."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKgS3_SWkYfz",
        "outputId": "b3e1c365-6cf7-4b0b-addf-15d18a816c02"
      },
      "source": [
        "tokens = set()\n",
        "\n",
        "for name in names:\n",
        "    tokens.update(set(name))\n",
        "tokens = sorted(list(tokens))  # <list of all unique characters in the dataset>\n",
        "\n",
        "num_tokens = len(tokens)\n",
        "print(\"num_tokens = \", num_tokens)\n",
        "\n",
        "#assert (\n",
        "#    50 < num_tokens < 60\n",
        "#), \"Names should contain within 50 and 60 unique tokens depending on encoding\"\n",
        "\n",
        "# <dictionary of symbol -> its identifier (index in tokens list)>\n",
        "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
        "\n",
        "for i in range(num_tokens):\n",
        "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_tokens =  27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N58SOXVCk21L"
      },
      "source": [
        "import numpy as np\n",
        "def to_matrix(names, max_len=None, pad=token_to_id[\" \"], dtype=\"int32\", batch_first=True):\n",
        "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
        "\n",
        "    names=list([names])\n",
        "\n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        line_ix = [token_to_id[c] for c in names[i]]\n",
        "        names_ix[i, : len(line_ix)] = line_ix\n",
        "\n",
        "    if not batch_first:  # convert [batch, time] into [time, batch]\n",
        "        names_ix = np.transpose(names_ix)\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykpqa-wtk9jA",
        "outputId": "ba323834-0d7c-40ca-e493-b4869b0aae49"
      },
      "source": [
        "# Example: cast 4 random names to matrices, pad with zeros\n",
        "#print(\"\\n\".join(names[:5]))\n",
        "#namesn=list([names])\n",
        "print(to_matrix(names[:25]))\n"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  6 18 15 13  0  6  1  9 18  5 19 20  0  3 18  5  1 20 21 18  5 19\n",
            "   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n45ATG_hlIcU"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "class CharRNNCell(nn.Module):\n",
        "    \"\"\"\n",
        "    Implement the scheme above as torch module\n",
        "    \"\"\"\n",
        "\n",
        "    #def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n",
        "    def __init__(self, num_tokens=len(tokens), embedding_size=32, rnn_num_units=128):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.num_units = rnn_num_units\n",
        "\n",
        "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
        "        self.rnn_update = nn.Linear(embedding_size + rnn_num_units, rnn_num_units)\n",
        "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        \"\"\"\n",
        "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
        "        We'll call it repeatedly to produce the whole sequence.\n",
        "\n",
        "        :param x: batch of character ids, containing vector of int64\n",
        "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
        "        \"\"\"\n",
        "        # get vector embedding of x\n",
        "        # batch, seq leng, emb dim\n",
        "        x_emb = self.embedding(x)\n",
        "\n",
        "        # compute next hidden state using self.rnn_update\n",
        "        # hint: use torch.cat(..., dim=...) for concatenation\n",
        "        x_and_h = torch.cat([x_emb, h_prev], dim=-1)  # YOUR CODE HERE\n",
        "        h_next = self.rnn_update(x_and_h)  # YOUR CODE HERE\n",
        "\n",
        "        h_next = torch.tanh(h_next)  # YOUR CODE HERE\n",
        "\n",
        "        assert h_next.size() == h_prev.size()\n",
        "\n",
        "        # compute logits for next character probs\n",
        "        logits = self.rnn_to_logits(h_next)  # YOUR CODE\n",
        "\n",
        "        return h_next, logits\n",
        "\n",
        "    def initial_state(self, batch_size):\n",
        "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
        "        return torch.zeros(batch_size, self.num_units, requires_grad=True)"
      ],
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUitsztplRqT"
      },
      "source": [
        "char_rnn = CharRNNCell()\n",
        "criterion = nn.NLLLoss()  # YOUR CODE HERE"
      ],
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-tbIPDQpHAE"
      },
      "source": [
        "**RNN LOOP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0n2YPF1lVh8"
      },
      "source": [
        "def rnn_loop(char_rnn, batch_ix):\n",
        "    \"\"\"\n",
        "    Computes log P(next_character) for all time-steps in names_ix\n",
        "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
        "    \"\"\"\n",
        "    batch_size, max_length = batch_ix.size()\n",
        "    hid_state = char_rnn.initial_state(batch_size)\n",
        "    logprobs = []\n",
        "\n",
        "    for x_t in batch_ix.transpose(0, 1):\n",
        "        hid_state, logits = char_rnn(x_t, hid_state)  # <-- here we call your one-step code\n",
        "        logprobs.append(F.log_softmax(logits, -1))\n",
        "\n",
        "    return torch.stack(logprobs, dim=1)"
      ],
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK1qHZQslYMl",
        "outputId": "7e070c45-c4ab-4b99-a36d-8b8f5127ed86"
      },
      "source": [
        "#batch_ix = to_matrix(names[:5])\n",
        "batch_ix = to_matrix(names[:200]) #increased for generating sentences\n",
        "batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
        "\n",
        "logp_seq = rnn_loop(char_rnn, batch_ix)\n",
        "\n",
        "assert torch.max(logp_seq).data.numpy() <= 0\n",
        "assert tuple(logp_seq.size()) == batch_ix.shape + (num_tokens,)\n",
        "logp_seq.shape"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 200, 27])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H35k_crso_Db"
      },
      "source": [
        "Likelihood and gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-tUOuF7ll8e"
      },
      "source": [
        "predictions_logp = logp_seq[:, :-1]\n",
        "actual_next_tokens = batch_ix[:, 1:]\n",
        "\n",
        "# .contiguous() method checks that tensor is stored in the memory correctly to\n",
        "# get its view of desired shape.\n",
        "\n",
        "loss = criterion(\n",
        "    predictions_logp.contiguous().view(-1, num_tokens),\n",
        "    actual_next_tokens.contiguous().view(-1),\n",
        ")"
      ],
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxYh6XRllowH"
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx9jEfoKlqaB"
      },
      "source": [
        "for w in char_rnn.parameters():\n",
        "    assert (\n",
        "        w.grad is not None and torch.max(torch.abs(w.grad)).data.numpy() != 0\n",
        "    ), \"Loss is not differentiable w.r.t. a weight with shape %s. Check forward method.\" % (\n",
        "        w.size(),\n",
        "    )"
      ],
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38fxOoVjmed4"
      },
      "source": [
        "**Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlZmPifCltNB"
      },
      "source": [
        "from random import sample\n",
        "from IPython.display import clear_output\n",
        "\n",
        "MAX_LENGTH=100\n",
        "\n",
        "char_rnn = CharRNNCell()\n",
        "criterion = nn.NLLLoss()\n",
        "opt = torch.optim.Adam(char_rnn.parameters())\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    opt.zero_grad()\n",
        "      \n",
        "    #batch_ix = to_matrix(sample(names, 32), max_len=MAX_LENGTH)\n",
        "    #подкладываю рандомные слова\n",
        "    batch_ix = to_matrix(random.choice(names.split()), max_len=MAX_LENGTH)\n",
        "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
        "\n",
        "    logp_seq = rnn_loop(char_rnn, batch_ix)\n",
        "\n",
        "    # compute loss\n",
        "    predictions_logp = logp_seq[:, :-1]  # YOUR CODE HERE\n",
        "    actual_next_tokens = batch_ix[:, 1:]  # YOUR CODE HERE\n",
        "\n",
        "    #     print(predictions_logp.shape, actual_next_tokens.shape)\n",
        "    loss = criterion(\n",
        "        predictions_logp.contiguous().view(-1, num_tokens),\n",
        "        actual_next_tokens.contiguous().view(-1),\n",
        "    )\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    # train with backprop\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    # HISTORY MOVED TO SEPARATE SNIPPET\n",
        "    history.append(loss.data.numpy())\n"
      ],
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gveyFkPkmkWh"
      },
      "source": [
        "**Generate samples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ldv4OHXgmXR7"
      },
      "source": [
        "def generate_sample(char_rnn, seed_phrase=\" \", max_length=MAX_LENGTH, temperature=1.0):\n",
        "    \"\"\"\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
        "                        smaller temperature converges to the single most likely output\n",
        "    \"\"\"\n",
        "\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
        "    hid_state = char_rnn.initial_state(batch_size=1)\n",
        "\n",
        "    # feed the seed phrase, if any\n",
        "    for i in range(len(seed_phrase) - 1):\n",
        "        hid_state, _ = char_rnn(x_sequence[:, i], hid_state)\n",
        "\n",
        "    # start generating\n",
        "    for _ in range(max_length - len(seed_phrase)):\n",
        "        hid_state, logits = char_rnn(x_sequence[:, -1], hid_state)\n",
        "        p_next = F.softmax(logits / temperature, dim=-1).data.numpy()[0]\n",
        "\n",
        "        # sample next token and push it back into x_sequence\n",
        "        next_ix = np.random.choice(num_tokens, p=p_next)\n",
        "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
        "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
        "\n",
        "    return \"\".join([tokens[ix] for ix in x_sequence.data.numpy()[0]])"
      ],
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03cB5R-OoqpZ"
      },
      "source": [
        "**Generate text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBo81nfhPOvu"
      },
      "source": [
        "# An example of generated text. There is no function `generate_text` in the code above.\n",
        "# print(generate_text(length=500, temperature=0.2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaVIS8Qxmtf4",
        "outputId": "c9091cb7-2320-4ec0-cbae-c4094558ca43"
      },
      "source": [
        "for _ in range(3):\n",
        "    print(generate_sample(char_rnn))"
      ],
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                                                                    \n",
            "                                                                                                    \n",
            "                                                                                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "UtVp8i6jm0di",
        "outputId": "c681d696-9542-4c4b-839d-83a1b9410471"
      },
      "source": [
        "for _ in range(3):\n",
        "    print(generate_sample(char_rnn, seed_phrase=\" Al\"))"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-278-8981a7a7b0b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_phrase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" Al\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-260-587194079e29>\u001b[0m in \u001b[0;36mgenerate_sample\u001b[0;34m(char_rnn, seed_phrase, max_length, temperature)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mx_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseed_phrase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mx_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_sequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mhid_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-260-587194079e29>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mx_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseed_phrase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mx_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_sequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mhid_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'A'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdYhz-tGnCfN",
        "outputId": "28557224-d888-4164-ff0d-189f024b9f43"
      },
      "source": [
        "for _ in range(3):\n",
        "    print(generate_sample(char_rnn, temperature=1))"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                                                                    \n",
            "                                                                                                    \n",
            "                                                                                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAmtBcRAbS6f"
      },
      "source": [
        "ee=ssss.split() \n",
        "import random \n",
        "random.choice(ee)\n",
        "ssss='asd asd asdasd sdf sd'\n",
        "\n",
        "#for i in ee:\n",
        "#  print(i)\n",
        "\n"
      ],
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXpgZ1JtjKB7"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1bYHnB9POvt"
      },
      "source": [
        "Plot the loss function (axis X: number of epochs, axis Y: loss function)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "l33YtZ0iPOvu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5193d53d-7958-4b46-f746-d710508a5157"
      },
      "source": [
        "# Your plot code here\n",
        "if (i + 1) % 100 == 0:\n",
        "    clear_output(True)\n",
        "    plt.plot(history, label=\"loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "#assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUosnNZEPOvv"
      },
      "source": [
        "### More poetic model\n",
        "\n",
        "Let's use LSTM instead of vanilla RNN and compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7p6YsLpPOvv"
      },
      "source": [
        "Plot the loss function of the number of epochs. Does the final loss become better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "KZeWrdlUPOvv"
      },
      "source": [
        "# Your beautiful code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHtfrgBoPOvw"
      },
      "source": [
        "Generate text using the trained net with different `temperature` parameter: `[0.1, 0.2, 0.5, 1.0, 2.0]`.\n",
        "\n",
        "Evaluate the results visually, try to interpret them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "5DiP7G2aPOvw"
      },
      "source": [
        "# Text generation with different temperature values here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XSgbUlCPOvx"
      },
      "source": [
        "### Saving and loading models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khe9kdFMPOvx"
      },
      "source": [
        "Save the model to the disk, then load it and generate text. Examples are available [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "WhH2gmdtPOvx"
      },
      "source": [
        "# Saving and loading code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLhhvurXPOvx"
      },
      "source": [
        "### References\n",
        "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Andrew Karpathy blog post about RNN. </a> \n",
        "There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n",
        "2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n",
        "3. Cool repo with PyTorch examples: [link](https://github.com/spro/practical-pytorch`)"
      ]
    }
  ]
}